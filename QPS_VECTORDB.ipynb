{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a recommendation system based on the given descriptions involves the following steps:\n",
        "\n",
        "# PDF Content Handling: Convert the text data in PDFs into embeddings using a Hugging Face model.\n",
        "# Embedding Storage: Store these embeddings in various vector databases: FAISS, Pinecone, Chroma.\n",
        "# Query System: Implement a similarity-based query system to find the most relevant category descriptions.\n",
        "# Performance Metrics: Measure execution time, Queries Per Second (QPS), and provide a cost comparison for each vector database.\n",
        "# Hereâ€™s the detailed implementation:"
      ],
      "metadata": {
        "id": "Og79obymKhBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Required Libraries\n",
        "!pip install fpdf transformers sentence-transformers faiss-cpu fitz PyMuPDF pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNtmwNVCpjvR",
        "outputId": "6737b01e-92ae-4291-9348-462b449f4aaa"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.13)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (7.1.0)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.3.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.2.2)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.2.0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (6.4.5)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.3)\n",
            "Requirement already satisfied: traits!=5.0,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.4.3)\n",
            "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.28)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (5.3.0)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.16.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "#Build PDF and description for Data\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Initialize descriptions for each category\n",
        "category_descriptions = {\n",
        "    \"sports\": (\n",
        "        \"Sports involve physical activities, team collaborations, strategic gameplay, \"\n",
        "        \"and bring excitement to millions globally. This category includes football, basketball, \"\n",
        "        \"tennis, and more, each with unique skills, fans, and thrilling competitions. \"\n",
        "        \"From Olympic games to local tournaments, sports bring together players and audiences, \"\n",
        "        \"celebrating endurance, speed, and agility...\"\n",
        "    ),\n",
        "    \"entertainment\": (\n",
        "        \"Entertainment encompasses films, music, theater, and digital content, shaping culture and \"\n",
        "        \"delivering stories that capture imaginations. With global movie industries like Hollywood, \"\n",
        "        \"Bollywood, and K-Pop taking the stage, entertainment offers a blend of art, creativity, \"\n",
        "        \"and visual storytelling that transcends borders...\"\n",
        "    ),\n",
        "    \"politics\": (\n",
        "        \"Politics is the realm of governance, policy-making, and leadership that drives nations. \"\n",
        "        \"It includes decision-making, diplomatic relations, and power dynamics among leaders and parties. \"\n",
        "        \"Political discourse shapes laws, human rights, and societal progress, with democracy, autocracy, \"\n",
        "        \"and other systems providing diverse approaches to leadership...\"\n",
        "    ),\n",
        "    \"electronics\": (\n",
        "        \"Electronics encompasses devices and systems that transform daily life, from smartphones \"\n",
        "        \"and laptops to complex circuits and AI technology. This field constantly innovates, pushing \"\n",
        "        \"boundaries with gadgets that improve connectivity, efficiency, and entertainment experiences. \"\n",
        "        \"In recent years, advancements in IoT, robotics, and machine learning have redefined possibilities...\"\n",
        "    ),\n",
        "    \"nature\": (\n",
        "        \"Nature includes ecosystems, wildlife, landscapes, and the fundamental elements of Earth. \"\n",
        "        \"From forests and oceans to mountains and deserts, nature provides resources, beauty, and sustenance. \"\n",
        "        \"With climate change becoming a pressing concern, efforts to conserve biodiversity and protect natural \"\n",
        "        \"habitats have grown, drawing attention to sustainable living and environmental responsibility...\"\n",
        "    ),\n",
        "    \"healthcare\": (\n",
        "        \"Healthcare revolves around promoting health, preventing diseases, and treating illnesses. \"\n",
        "        \"It involves hospitals, clinics, medical research, and technologies like telemedicine and AI-powered diagnostics. \"\n",
        "        \"Advancements in medicine, public health initiatives, and awareness campaigns have improved life expectancy \"\n",
        "        \"and quality of life globally...\"\n",
        "    ),\n",
        "    \"education\": (\n",
        "        \"Education empowers individuals with knowledge, skills, and values needed for personal and societal growth. \"\n",
        "        \"It spans primary schooling to higher education and online platforms that make learning accessible worldwide. \"\n",
        "        \"Education systems play a pivotal role in shaping future generations and driving innovation and cultural progress...\"\n",
        "    ),\n",
        "    \"technology\": (\n",
        "        \"Technology is the backbone of modern civilization, encompassing software, hardware, and cutting-edge innovations. \"\n",
        "        \"It drives industries, connects people through the internet, and creates tools that solve complex problems. \"\n",
        "        \"From blockchain to artificial intelligence, technology continues to redefine the boundaries of what's possible...\"\n",
        "    ),\n",
        "    \"travel\": (\n",
        "        \"Travel allows individuals to explore new cultures, cuisines, and landscapes, broadening horizons and creating memories. \"\n",
        "        \"From adventurous treks to luxury cruises, travel experiences vary widely, catering to diverse preferences. \"\n",
        "        \"The tourism industry, while impacted by global events, remains a vital part of economic and cultural exchange...\"\n",
        "    ),\n",
        "    \"finance\": (\n",
        "        \"Finance involves managing money, investments, and economic activities. \"\n",
        "        \"It encompasses banking, stock markets, personal financial planning, and global trade. \"\n",
        "        \"With fintech innovations and a growing emphasis on digital currencies, finance is transforming rapidly to adapt to the modern world...\"\n",
        "    )\n",
        "}\n",
        "\n",
        "# Function to create PDF with a given category and description\n",
        "def create_pdf(category, description):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "    # Title of the category\n",
        "    pdf.set_font(\"Arial\", \"B\", 16)\n",
        "    pdf.cell(200, 10, f\"{category.capitalize()} Overview\", ln=True, align=\"C\")\n",
        "\n",
        "    # Content description\n",
        "    pdf.set_font(\"Arial\", \"\", 12)\n",
        "    pdf.ln(10)\n",
        "    pdf.multi_cell(0, 10, description)\n",
        "\n",
        "    # Save the PDF\n",
        "    pdf_filename = f\"{category}_description.pdf\"\n",
        "    pdf.output(pdf_filename)\n",
        "    print(f\"{pdf_filename} created successfully.\")\n",
        "\n",
        "# Generate PDFs for all categories\n",
        "for category, description in category_descriptions.items():\n",
        "    create_pdf(category, description)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ArR8s3spuMX",
        "outputId": "a6b7c51a-1320-4894-ef47-d6fa5d68f1dd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sports_description.pdf created successfully.\n",
            "entertainment_description.pdf created successfully.\n",
            "politics_description.pdf created successfully.\n",
            "electronics_description.pdf created successfully.\n",
            "nature_description.pdf created successfully.\n",
            "healthcare_description.pdf created successfully.\n",
            "education_description.pdf created successfully.\n",
            "technology_description.pdf created successfully.\n",
            "travel_description.pdf created successfully.\n",
            "finance_description.pdf created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Convert Text Descriptions into Embeddings\n",
        "# We will use a Hugging Face model like sentence-transformers to generate embeddings for the descriptions in the PDFs.\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "\n",
        "# Initialize the model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Example: Load text descriptions\n",
        "category_descriptions = {\n",
        "    \"sports\": \"Sports involve physical activities...\",\n",
        "    \"entertainment\": \"Entertainment encompasses films...\",\n",
        "    \"politics\": \"Politics is the realm of governance...\",\n",
        "    \"electronics\": \"Electronics encompasses devices...\",\n",
        "    \"nature\": \"Nature includes ecosystems...\",\n",
        "    \"finance\":\"Finance involves managing money, investments, and economic activities... \",\n",
        "    \"travel\": \"Travel allows individuals to explore new cultures, cuisines... \",\n",
        "    \"technology\": \"Technology is the backbone of modern civilization...\",\n",
        "    \"healthcare\": \"Healthcare revolves around promoting health...\",\n",
        "    \"education\": \"Education empowers individuals with knowledge...\"\n",
        "\n",
        "}\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = {category: model.encode(description) for category, description in category_descriptions.items()}\n",
        "print(\"Embeddings generated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4rvy70bp2jk",
        "outputId": "96ec6a93-1c03-410f-86d2-4004afd432de"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Data: Category descriptions\n",
        "category_descriptions = {\n",
        "    \"sports\": \"Sports involve physical activities...\",\n",
        "    \"entertainment\": \"Entertainment encompasses films...\",\n",
        "    \"politics\": \"Politics is the realm of governance...\",\n",
        "    \"electronics\": \"Electronics encompasses devices...\",\n",
        "    \"nature\": \"Nature includes ecosystems...\",\n",
        "    \"finance\": \"Finance involves managing money, investments, and economic activities...\",\n",
        "    \"travel\": \"Travel allows individuals to explore new cultures, cuisines...\",\n",
        "    \"technology\": \"Technology is the backbone of modern civilization...\",\n",
        "    \"healthcare\": \"Healthcare revolves around promoting health...\",\n",
        "    \"education\": \"Education empowers individuals with knowledge...\"\n",
        "}\n",
        "\n",
        "# Step 1: Load Hugging Face Transformer Model for Embedding Generation\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_embedding(text):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# Step 2: Generate Embeddings for All Descriptions\n",
        "descriptions = list(category_descriptions.values())\n",
        "categories = list(category_descriptions.keys())\n",
        "\n",
        "embeddings = np.array([generate_embedding(desc) for desc in descriptions]).astype(\"float32\")\n",
        "\n",
        "# Step 3: Initialize FAISS Index\n",
        "embedding_dim = embeddings.shape[1]  # Get the dimension of embeddings\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 distance (Euclidean)\n",
        "index.add(embeddings)  # Add embeddings to the FAISS index\n",
        "print(f\"FAISS index contains {index.ntotal} embeddings.\")\n",
        "\n",
        "# Step 4: Define a function for Querying and measuring time\n",
        "def measure_query_performance(query_description, k=5):\n",
        "    query_embedding = generate_embedding(query_description).astype(\"float32\").reshape(1, -1)  # Query embedding\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform the similarity search\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Record end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time it took for the query to execute\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    # Return the results and the query execution time\n",
        "    results = [(categories[indices[0][i]], distances[0][i]) for i in range(k)]\n",
        "    return results, query_time\n",
        "\n",
        "# Step 5: Run multiple queries and calculate QPS\n",
        "num_queries = 100  # Number of queries to perform\n",
        "total_time = 0\n",
        "for _ in range(num_queries):\n",
        "    query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "    results, query_time = measure_query_performance(query_description)\n",
        "    total_time += query_time\n",
        "\n",
        "# Calculate QPS (queries per second)\n",
        "qps = num_queries / total_time\n",
        "\n",
        "# Display Results\n",
        "print(f\"Average Query Time: {total_time / num_queries:.6f} seconds\")\n",
        "print(f\"Queries Per Second (QPS): {qps:.2f}\")\n",
        "\n",
        "# Step 6: Perform Similarity Search for a single query\n",
        "query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "query_embedding = generate_embedding(query_description).astype(\"float32\").reshape(1, -1)  # Query embedding\n",
        "\n",
        "k = 5  # Number of top results to retrieve\n",
        "distances, indices = index.search(query_embedding, k)  # Search in FAISS\n",
        "\n",
        "# Step 7: Display Results for the query\n",
        "print(\"Query Description:\", query_description)\n",
        "print(\"\\nTop Results:\")\n",
        "for i in range(k):\n",
        "    print(f\"Category: {categories[indices[0][i]]}, Distance: {distances[0][i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLuLXCuFpw6S",
        "outputId": "3a0dbf8a-f8b3-429d-a359-a11da53dcee3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index contains 10 embeddings.\n",
            "Average Query Time: 0.000053 seconds\n",
            "Queries Per Second (QPS): 18912.00\n",
            "Query Description: Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\n",
            "\n",
            "Top Results:\n",
            "Category: sports, Distance: 14.87306022644043\n",
            "Category: travel, Distance: 26.612308502197266\n",
            "Category: healthcare, Distance: 30.658266067504883\n",
            "Category: entertainment, Distance: 33.25926971435547\n",
            "Category: finance, Distance: 34.60906982421875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pinecone"
      ],
      "metadata": {
        "id": "zzZ7_T8lrWmr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "# Data: Category descriptions\n",
        "category_descriptions = {\n",
        "    \"sports\": \"Sports involve physical activities...\",\n",
        "    \"entertainment\": \"Entertainment encompasses films...\",\n",
        "    \"politics\": \"Politics is the realm of governance...\",\n",
        "    \"electronics\": \"Electronics encompasses devices...\",\n",
        "    \"nature\": \"Nature includes ecosystems...\",\n",
        "    \"finance\": \"Finance involves managing money, investments, and economic activities...\",\n",
        "    \"travel\": \"Travel allows individuals to explore new cultures, cuisines...\",\n",
        "    \"technology\": \"Technology is the backbone of modern civilization...\",\n",
        "    \"healthcare\": \"Healthcare revolves around promoting health...\",\n",
        "    \"education\": \"Education empowers individuals with knowledge...\"\n",
        "}\n",
        "\n",
        "# Step 1: Hugging Face Model for Embedding Generation\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_embedding(text):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# Step 2: Initialize Pinecone\n",
        "pc = pinecone.Pinecone(api_key=\"pcsk_vnBRv_2ME4BgyQYJUrVU5dG8ASkwbB84aDaEPMZNrZPAXUyBp61ANqDqEG3vHxrf641c7\", environment=\"us-east-1\")\n",
        "\n",
        "# Define index name and dimension\n",
        "index_name = \"category-descriptions\"\n",
        "dimension = 384\n",
        "\n",
        "# Create the index if it doesn't exist\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=dimension,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "# Step 3: Generate Embeddings for All Descriptions\n",
        "descriptions = list(category_descriptions.values())\n",
        "categories = list(category_descriptions.keys())\n",
        "\n",
        "embeddings = np.array([generate_embedding(desc) for desc in descriptions]).astype(\"float32\")\n",
        "\n",
        "# Step 4: Create Pinecone Index (if not already created)\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Step 5: Insert embeddings into Pinecone\n",
        "vectors = [(str(i), embeddings[i]) for i in range(len(embeddings))]\n",
        "index.upsert(vectors)\n",
        "\n",
        "print(f\"Pinecone index contains {len(vectors)} embeddings.\")\n",
        "\n",
        "# Step 6: Define a function for Querying and measuring time\n",
        "def measure_query_performance(query_description, k=5):\n",
        "    query_embedding = generate_embedding(query_description).astype(\"float32\")  # Query embedding\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform the similarity search using keyword arguments\n",
        "    query_result = index.query(vector=query_embedding.tolist(), top_k=k, include_values=True)\n",
        "\n",
        "    # Record end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time it took for the query to execute\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    # Return the results and the query execution time\n",
        "    results = [(result[\"id\"], result[\"score\"]) for result in query_result[\"matches\"]]\n",
        "    return results, query_time\n",
        "\n",
        "# Step 7: Run multiple queries and calculate QPS\n",
        "num_queries = 100  # Number of queries to perform\n",
        "total_time = 0\n",
        "for i in range(num_queries):\n",
        "    query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "    results, query_time = measure_query_performance(query_description, k=5)\n",
        "    total_time += query_time\n",
        "    if i == 0:  # Only print results once for the first query\n",
        "        print(\"Query Results Structure:\")\n",
        "        for category, score in results:\n",
        "            print(f\"Category: {category}, Score: {score}\")\n",
        "\n",
        "# Calculate QPS (queries per second)\n",
        "qps = num_queries / total_time\n",
        "\n",
        "# Display Results\n",
        "print(f\"Average Query Time: {total_time / num_queries:.6f} seconds\")\n",
        "print(f\"Queries Per Second (QPS): {qps:.2f}\")\n",
        "\n",
        "# Step 8: Perform Similarity Search for a single query\n",
        "query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "results, query_time = measure_query_performance(query_description, k=5)\n",
        "\n",
        "# Step 9: Display Results for the query\n",
        "print(\"Query Description:\", query_description)\n",
        "print(\"\\nTop Results:\")\n",
        "for category, score in results:\n",
        "    print(f\"Category: {category}, Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6zAq_sWvxTC",
        "outputId": "ce95dcf1-1639-47bc-e3b4-92f5ba073f7d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone index contains 10 embeddings.\n",
            "Query Results Structure:\n",
            "Category: 0, Score: 0.677599549\n",
            "Category: sports, Score: 0.677599549\n",
            "Category: 1, Score: 0.424011499\n",
            "Category: entertainment, Score: 0.424011499\n",
            "Category: 6, Score: 0.331266254\n",
            "Average Query Time: 0.051074 seconds\n",
            "Queries Per Second (QPS): 19.58\n",
            "Query Description: Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\n",
            "\n",
            "Top Results:\n",
            "Category: sports, Score: 0.677599549\n",
            "Category: 0, Score: 0.677599549\n",
            "Category: entertainment, Score: 0.424011499\n",
            "Category: 1, Score: 0.424011499\n",
            "Category: travel, Score: 0.331266254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chroma db"
      ],
      "metadata": {
        "id": "xcPMXx-9LKmG"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb sentence-transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHBzZWwSsZms",
        "outputId": "288ed29c-f5cc-447a-f2c4-dafbb0e02e25"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.18)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.5)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.67.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete each collection by name"
      ],
      "metadata": {
        "id": "q77touVQLOXw"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "# Step 1: Initialize Chroma Client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Step 2: List all collections\n",
        "collections = client.list_collections()\n",
        "\n",
        "# Step 3: Delete each collection by name\n",
        "for collection in collections:\n",
        "    collection_name = collection.name  # Access the collection name\n",
        "    client.delete_collection(collection_name)\n",
        "    print(f\"Collection '{collection_name}' has been deleted.\")\n",
        "\n",
        "# Verify that all collections have been deleted\n",
        "remaining_collections = client.list_collections()\n",
        "if not remaining_collections:\n",
        "    print(\"All collections have been deleted.\")\n",
        "else:\n",
        "    print(f\"Remaining collections: {remaining_collections}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p-yr8ZKtjWc",
        "outputId": "eff1c76a-403c-470a-9b33-a61c803c348d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'category_descriptions' has been deleted.\n",
            "All collections have been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "# Step 1: Initialize Chroma Client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Step 2: Specify the collection name to delete\n",
        "collection_name = \"category_collection\"\n",
        "\n",
        "# Step 3: Check if the collection exists and delete it\n",
        "if collection_name in client.list_collections():\n",
        "    client.delete_collection(collection_name)\n",
        "    print(f\"Collection '{collection_name}' has been deleted.\")\n",
        "else:\n",
        "    print(f\"Collection '{collection_name}' does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHO_Vm7HtT-8",
        "outputId": "751a0e5b-8c74-47b8-b42c-88c8772bbed6"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'category_collection' does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Data: Category descriptions\n",
        "category_descriptions = {\n",
        "    \"sports\": \"Sports involve physical activities...\",\n",
        "    \"entertainment\": \"Entertainment encompasses films...\",\n",
        "    \"politics\": \"Politics is the realm of governance...\",\n",
        "    \"electronics\": \"Electronics encompasses devices...\",\n",
        "    \"nature\": \"Nature includes ecosystems...\",\n",
        "    \"finance\": \"Finance involves managing money, investments, and economic activities...\",\n",
        "    \"travel\": \"Travel allows individuals to explore new cultures, cuisines...\",\n",
        "    \"technology\": \"Technology is the backbone of modern civilization...\",\n",
        "    \"healthcare\": \"Healthcare revolves around promoting health...\",\n",
        "    \"education\": \"Education empowers individuals with knowledge...\"\n",
        "}\n",
        "\n",
        "# Initialize Chroma Client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Step 1: Load Hugging Face Transformer Model for Embedding Generation\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_embedding(text):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# Step 2: Generate Embeddings for All Descriptions\n",
        "descriptions = list(category_descriptions.values())\n",
        "categories = list(category_descriptions.keys())\n",
        "\n",
        "embeddings = np.array([generate_embedding(desc) for desc in descriptions]).astype(\"float32\")\n",
        "\n",
        "# Step 3: Initialize Chroma Collection and Add Data\n",
        "collection_name = \"category_collection\"\n",
        "collection = client.create_collection(name=collection_name)\n",
        "\n",
        "# Insert data into the collection with unique ids\n",
        "for idx, (category, description) in enumerate(zip(categories, descriptions)):\n",
        "    embedding = generate_embedding(description)\n",
        "    collection.add(\n",
        "        ids=[str(idx)],  # Unique ID for each document (can use the index as the ID)\n",
        "        documents=[description],\n",
        "        metadatas=[{\"category\": category, \"description\": description}],\n",
        "        embeddings=[embedding]\n",
        "    )\n",
        "\n",
        "# Step 4: Define a function for Querying and measuring time\n",
        "def measure_query_performance(query_description, k=5):\n",
        "    query_embedding = generate_embedding(query_description).astype(\"float32\").reshape(1, -1)  # Query embedding\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Perform the similarity search\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding,\n",
        "        n_results=k\n",
        "    )\n",
        "\n",
        "    # Record end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time it took for the query to execute\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    # Step 5: Process the results based on the printed structure\n",
        "    try:\n",
        "        result_categories = [\n",
        "            (metadata[\"category\"], distance)\n",
        "            for metadata, distance in zip(results[\"metadatas\"][0], results[\"distances\"][0])\n",
        "        ]\n",
        "    except TypeError as e:\n",
        "        print(f\"Error accessing results: {e}\")\n",
        "        result_categories = []\n",
        "\n",
        "    return result_categories, query_time\n",
        "\n",
        "# Step 6: Run multiple queries and calculate QPS\n",
        "num_queries = 100  # Number of queries to perform\n",
        "total_time = 0\n",
        "results_list = []\n",
        "for i in range(num_queries):\n",
        "    query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "    results, query_time = measure_query_performance(query_description)\n",
        "    total_time += query_time\n",
        "    if i == 0:  # Only print results once for the first query\n",
        "        print(\"Query Results Structure:\")\n",
        "        print(results)\n",
        "\n",
        "# Calculate QPS (queries per second)\n",
        "qps = num_queries / total_time\n",
        "\n",
        "# Display Results\n",
        "print(f\"Average Query Time: {total_time / num_queries:.6f} seconds\")\n",
        "print(f\"Queries Per Second (QPS): {qps:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ngEJCpCrhox",
        "outputId": "792605f0-bcc9-4444-e894-14609a8c238d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Results Structure:\n",
            "[('sports', 14.873058319091797), ('travel', 26.612308502197266), ('healthcare', 30.658266067504883), ('entertainment', 33.25926971435547), ('finance', 34.60906982421875)]\n",
            "Average Query Time: 0.003128 seconds\n",
            "Queries Per Second (QPS): 319.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "# Step 1: Initialize Chroma Client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Step 2: List all collections\n",
        "collections = client.list_collections()\n",
        "\n",
        "# Step 3: Delete each collection by name\n",
        "for collection in collections:\n",
        "    collection_name = collection.name  # Access the collection name\n",
        "    client.delete_collection(collection_name)\n",
        "    print(f\"Collection '{collection_name}' has been deleted.\")\n",
        "\n",
        "# Verify that all collections have been deleted\n",
        "remaining_collections = client.list_collections()\n",
        "if not remaining_collections:\n",
        "    print(\"All collections have been deleted.\")\n",
        "else:\n",
        "    print(f\"Remaining collections: {remaining_collections}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu3jAzYXLXpR",
        "outputId": "22c49eee-80f0-4d9a-ae7b-b883fd7f3a89"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'category_collection' has been deleted.\n",
            "All collections have been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pinecone\n",
        "import chromadb\n",
        "import faiss\n",
        "import torch\n",
        "\n",
        "# Data: Category descriptions\n",
        "category_descriptions = {\n",
        "    \"sports\": \"Sports involve physical activities...\",\n",
        "    \"entertainment\": \"Entertainment encompasses films...\",\n",
        "    \"politics\": \"Politics is the realm of governance...\",\n",
        "    \"electronics\": \"Electronics encompasses devices...\",\n",
        "    \"nature\": \"Nature includes ecosystems...\",\n",
        "    \"finance\": \"Finance involves managing money, investments, and economic activities...\",\n",
        "    \"travel\": \"Travel allows individuals to explore new cultures, cuisines...\",\n",
        "    \"technology\": \"Technology is the backbone of modern civilization...\",\n",
        "    \"healthcare\": \"Healthcare revolves around promoting health...\",\n",
        "    \"education\": \"Education empowers individuals with knowledge...\"\n",
        "}\n",
        "\n",
        "# Step 1: Hugging Face Model for Embedding Generation\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_embedding(text):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# Step 2: Prepare Embeddings\n",
        "descriptions = list(category_descriptions.values())\n",
        "categories = list(category_descriptions.keys())\n",
        "\n",
        "embeddings = np.array([generate_embedding(desc) for desc in descriptions]).astype(\"float32\")\n",
        "\n",
        "# Step 3: Initialize Pinecone\n",
        "pc = pinecone.Pinecone(api_key=\"pcsk_vnBRv_2ME4BgyQYJUrVU5dG8ASkwbB84aDaEPMZNrZPAXUyBp61ANqDqEG3vHxrf641c7\", environment=\"us-east-1\")\n",
        "index_name = \"category-descriptions\"\n",
        "dimension = 384\n",
        "\n",
        "# Create Pinecone index if not exists\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(name=index_name, dimension=dimension, metric=\"cosine\")\n",
        "\n",
        "# Insert embeddings into Pinecone\n",
        "index = pc.Index(index_name)\n",
        "vectors = [(str(i), embeddings[i]) for i in range(len(embeddings))]\n",
        "index.upsert(vectors)\n",
        "\n",
        "# Step 4: Initialize Chroma\n",
        "\n",
        "client = chromadb.Client()\n",
        "chroma_collection = client.create_collection(\"category_descriptions\")\n",
        "\n",
        "# Adding embeddings to Chroma with unique IDs\n",
        "for idx, embedding in enumerate(embeddings):\n",
        "    chroma_collection.add(\n",
        "        ids=[str(idx)],  # Unique IDs for each entry\n",
        "        documents=[category_descriptions[categories[idx]]],\n",
        "        metadatas=[{\"category\": categories[idx]}],\n",
        "        embeddings=[embedding]\n",
        "    )\n",
        "# Step 5: Initialize FAISS\n",
        "index_faiss = faiss.IndexFlatL2(dimension)\n",
        "index_faiss.add(embeddings)\n",
        "\n",
        "# Step 6: Function to Measure Query Performance\n",
        "def measure_query_performance(query_description, k=5, method=\"pinecone\"):\n",
        "    query_embedding = generate_embedding(query_description).astype(\"float32\")  # Query embedding\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    if method == \"pinecone\":\n",
        "        query_result = index.query(vector=query_embedding.tolist(), top_k=k, include_values=True)\n",
        "        results = [(result[\"id\"], result[\"score\"]) for result in query_result[\"matches\"]]\n",
        "\n",
        "    elif method == \"chroma\":\n",
        "        results = chroma_collection.query(query_embeddings=[query_embedding], n_results=k)\n",
        "\n",
        "    elif method == \"faiss\":\n",
        "        D, I = index_faiss.search(np.array([query_embedding]), k)\n",
        "        results = [(categories[i], D[0][j]) for j, i in enumerate(I[0])]\n",
        "\n",
        "    # Record end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate query time\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    return results, query_time\n",
        "\n",
        "# Step 7: Run multiple queries and calculate QPS for all methods\n",
        "num_queries = 100  # Number of queries to perform\n",
        "methods = [\"pinecone\", \"chroma\", \"faiss\"]\n",
        "qps_results = {}\n",
        "\n",
        "for method in methods:\n",
        "    total_time = 0\n",
        "    for i in range(num_queries):\n",
        "        query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "        _, query_time = measure_query_performance(query_description, k=5, method=method)\n",
        "        total_time += query_time\n",
        "\n",
        "    qps = num_queries / total_time\n",
        "    qps_results[method] = {\n",
        "        \"avg_query_time\": total_time / num_queries,\n",
        "        \"qps\": qps\n",
        "    }\n",
        "\n",
        "# Step 8: Display Results\n",
        "for method in methods:\n",
        "    print(f\"Method: {method.capitalize()}\")\n",
        "    print(f\"Average Query Time: {qps_results[method]['avg_query_time']:.6f} seconds\")\n",
        "    print(f\"Queries Per Second (QPS): {qps_results[method]['qps']:.2f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPXCG6Gusmxs",
        "outputId": "c59eb0a4-8c1e-409d-80bb-14c3ed1d1c34"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: Pinecone\n",
            "Average Query Time: 0.061502 seconds\n",
            "Queries Per Second (QPS): 16.26\n",
            "--------------------------------------------------\n",
            "Method: Chroma\n",
            "Average Query Time: 0.004744 seconds\n",
            "Queries Per Second (QPS): 210.77\n",
            "--------------------------------------------------\n",
            "Method: Faiss\n",
            "Average Query Time: 0.000111 seconds\n",
            "Queries Per Second (QPS): 9039.45\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "# Step 1: Initialize Chroma Client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Step 2: List all collections\n",
        "collections = client.list_collections()\n",
        "\n",
        "# Step 3: Delete each collection by name\n",
        "for collection in collections:\n",
        "    collection_name = collection.name  # Access the collection name\n",
        "    client.delete_collection(collection_name)\n",
        "    print(f\"Collection '{collection_name}' has been deleted.\")\n",
        "\n",
        "# Verify that all collections have been deleted\n",
        "remaining_collections = client.list_collections()\n",
        "if not remaining_collections:\n",
        "    print(\"All collections have been deleted.\")\n",
        "else:\n",
        "    print(f\"Remaining collections: {remaining_collections}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOp7dA1TLdcH",
        "outputId": "63b92999-dcd3-4a77-8a05-487fa6f6601d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'category_descriptions' has been deleted.\n",
            "All collections have been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector db Comparision\n",
        "#QPS and Execution time."
      ],
      "metadata": {
        "id": "s45uWpV9Lluv"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pinecone\n",
        "import chromadb\n",
        "import faiss\n",
        "import torch\n",
        "\n",
        "# Data: Category descriptions\n",
        "category_descriptions = {\n",
        "    \"sports\": \"Sports involve physical activities...\",\n",
        "    \"entertainment\": \"Entertainment encompasses films...\",\n",
        "    \"politics\": \"Politics is the realm of governance...\",\n",
        "    \"electronics\": \"Electronics encompasses devices...\",\n",
        "    \"nature\": \"Nature includes ecosystems...\",\n",
        "    \"finance\": \"Finance involves managing money, investments, and economic activities...\",\n",
        "    \"travel\": \"Travel allows individuals to explore new cultures, cuisines...\",\n",
        "    \"technology\": \"Technology is the backbone of modern civilization...\",\n",
        "    \"healthcare\": \"Healthcare revolves around promoting health...\",\n",
        "    \"education\": \"Education empowers individuals with knowledge...\"\n",
        "}\n",
        "\n",
        "# Step 1: Hugging Face Model for Embedding Generation\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_embedding(text):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens).last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# Step 2: Prepare Embeddings\n",
        "descriptions = list(category_descriptions.values())\n",
        "categories = list(category_descriptions.keys())\n",
        "\n",
        "embeddings = np.array([generate_embedding(desc) for desc in descriptions]).astype(\"float32\")\n",
        "\n",
        "# Step 3: Initialize Pinecone\n",
        "pc = pinecone.Pinecone(api_key=\"pcsk_vnBRv_2ME4BgyQYJUrVU5dG8ASkwbB84aDaEPMZNrZPAXUyBp61ANqDqEG3vHxrf641c7\", environment=\"us-east-1\")\n",
        "index_name = \"category-descriptions\"\n",
        "dimension = 384\n",
        "\n",
        "# Create Pinecone index if not exists\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(name=index_name, dimension=dimension, metric=\"cosine\")\n",
        "\n",
        "# Insert embeddings into Pinecone\n",
        "index = pc.Index(index_name)\n",
        "vectors = [(str(i), embeddings[i]) for i in range(len(embeddings))]\n",
        "index.upsert(vectors)\n",
        "\n",
        "# Step 4: Initialize Chroma\n",
        "client = chromadb.Client()\n",
        "chroma_collection = client.create_collection(\"category_descriptions\")\n",
        "\n",
        "# Adding embeddings to Chroma with unique IDs\n",
        "for idx, embedding in enumerate(embeddings):\n",
        "    chroma_collection.add(\n",
        "        ids=[str(idx)],  # Unique IDs for each entry\n",
        "        documents=[category_descriptions[categories[idx]]],\n",
        "        metadatas=[{\"category\": categories[idx]}],\n",
        "        embeddings=[embedding]\n",
        "    )\n",
        "\n",
        "# Step 5: Initialize FAISS\n",
        "index_faiss = faiss.IndexFlatL2(dimension)\n",
        "index_faiss.add(embeddings)\n",
        "\n",
        "# Step 6: Function to Measure Query Performance\n",
        "def measure_query_performance(query_description, k=5, method=\"pinecone\"):\n",
        "    query_embedding = generate_embedding(query_description).astype(\"float32\")  # Query embedding\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    if method == \"pinecone\":\n",
        "        query_result = index.query(vector=query_embedding.tolist(), top_k=k, include_values=True)\n",
        "        results = [(result[\"id\"], result[\"score\"]) for result in query_result[\"matches\"]]\n",
        "\n",
        "    elif method == \"chroma\":\n",
        "        query_result = chroma_collection.query(query_embeddings=[query_embedding], n_results=k)\n",
        "\n",
        "        # Debugging: Print query result to inspect its structure\n",
        "        # print(\"Chroma Query Result:\", query_result)\n",
        "\n",
        "        # Extract results for Chroma based on the new structure\n",
        "        results = []\n",
        "        for idx in range(k):\n",
        "            document = query_result['documents'][0][idx]  # Document description\n",
        "            category = query_result['metadatas'][0][idx]['category']  # Category from metadata\n",
        "            score = query_result['distances'][0][idx]  # Similarity score (distance)\n",
        "            results.append((category, score))\n",
        "\n",
        "    elif method == \"faiss\":\n",
        "        D, I = index_faiss.search(np.array([query_embedding]), k)\n",
        "        results = [(categories[i], D[0][j]) for j, i in enumerate(I[0])]\n",
        "\n",
        "    # Record end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate query time\n",
        "    query_time = end_time - start_time\n",
        "\n",
        "    return results, query_time\n",
        "\n",
        "# Step 7: Run multiple queries and calculate QPS for all methods\n",
        "num_queries = 1  # Number of queries to perform\n",
        "methods = [\"pinecone\", \"chroma\", \"faiss\"]\n",
        "qps_results = {}\n",
        "\n",
        "all_results = {method: [] for method in methods}  # Store results for each method\n",
        "\n",
        "for method in methods:\n",
        "    total_time = 0\n",
        "    for i in range(num_queries):\n",
        "        query_description = \"Games that involve physical activities and bring excitement to audiences worldwide, like football and tennis.\"\n",
        "        results, query_time = measure_query_performance(query_description, k=5, method=method)\n",
        "        all_results[method].append(results)  # Store the results for each query\n",
        "        total_time += query_time\n",
        "\n",
        "    qps = num_queries / total_time\n",
        "    qps_results[method] = {\n",
        "        \"avg_query_time\": total_time / num_queries,\n",
        "        \"qps\": qps\n",
        "    }\n",
        "\n",
        "# Step 8: Display Results\n",
        "for method in methods:\n",
        "    print(f\"Method: {method.capitalize()}\")\n",
        "    print(f\"Average Query Time: {qps_results[method]['avg_query_time']:.6f} seconds\")\n",
        "    print(f\"Queries Per Second (QPS): {qps_results[method]['qps']:.2f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Display results for the first query for each method\n",
        "    print(\"Query Results (Cosine Similarity):\")\n",
        "    for idx, results in enumerate(all_results[method]):\n",
        "        print(f\"Query {idx + 1}:\")\n",
        "        for rank, (category, score) in enumerate(results, 1):\n",
        "            print(f\"Rank {rank}: Category: {category}, Cosine Similarity Score: {score}\")\n",
        "        print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4emQpZ9-m8_",
        "outputId": "eb4391b9-c40b-45bd-8c00-2714f895a2e9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: Pinecone\n",
            "Average Query Time: 0.087001 seconds\n",
            "Queries Per Second (QPS): 11.49\n",
            "--------------------------------------------------\n",
            "Query Results (Cosine Similarity):\n",
            "Query 1:\n",
            "Rank 1: Category: sports, Cosine Similarity Score: 0.677599549\n",
            "Rank 2: Category: 0, Cosine Similarity Score: 0.677441418\n",
            "Rank 3: Category: entertainment, Cosine Similarity Score: 0.424011499\n",
            "Rank 4: Category: 1, Cosine Similarity Score: 0.423690289\n",
            "Rank 5: Category: 6, Cosine Similarity Score: 0.331317544\n",
            "--------------------------------------------------\n",
            "Method: Chroma\n",
            "Average Query Time: 0.004972 seconds\n",
            "Queries Per Second (QPS): 201.13\n",
            "--------------------------------------------------\n",
            "Query Results (Cosine Similarity):\n",
            "Query 1:\n",
            "Rank 1: Category: sports, Cosine Similarity Score: 14.873058319091797\n",
            "Rank 2: Category: travel, Cosine Similarity Score: 26.612308502197266\n",
            "Rank 3: Category: healthcare, Cosine Similarity Score: 30.658266067504883\n",
            "Rank 4: Category: entertainment, Cosine Similarity Score: 33.25926971435547\n",
            "Rank 5: Category: finance, Cosine Similarity Score: 34.60906982421875\n",
            "--------------------------------------------------\n",
            "Method: Faiss\n",
            "Average Query Time: 0.000108 seconds\n",
            "Queries Per Second (QPS): 9258.95\n",
            "--------------------------------------------------\n",
            "Query Results (Cosine Similarity):\n",
            "Query 1:\n",
            "Rank 1: Category: sports, Cosine Similarity Score: 14.87306022644043\n",
            "Rank 2: Category: travel, Cosine Similarity Score: 26.612308502197266\n",
            "Rank 3: Category: healthcare, Cosine Similarity Score: 30.658266067504883\n",
            "Rank 4: Category: entertainment, Cosine Similarity Score: 33.25926971435547\n",
            "Rank 5: Category: finance, Cosine Similarity Score: 34.60906982421875\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GApm5HFz_wMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detailed Explanation of the Results:\n",
        "The comparison between the three methods (Pinecone, Chroma, and Faiss) provides insights into the performance and query results based on cosine similarity scores.\n",
        "\n",
        "1. Pinecone:\n",
        "Average Query Time: 0.087001 seconds\n",
        "This means on average, each query takes approximately 0.087 seconds to return results.\n",
        "Queries Per Second (QPS): 11.49\n",
        "This indicates that Pinecone can handle 11.49 queries per second.\n",
        "Query Results (Cosine Similarity):\n",
        "For Query 1, the cosine similarity scores show that the most similar category is sports, with a similarity score of 0.6776. The second-highest match is a category labeled as 0 (which may be a placeholder or misassigned category), followed by other categories like entertainment and numerical identifiers 1 and 6.\n",
        "2. Chroma:\n",
        "Average Query Time: 0.004972 seconds\n",
        "Chroma is significantly faster on average, processing each query in just about 0.005 seconds.\n",
        "Queries Per Second (QPS): 201.13\n",
        "This means that Chroma can handle over 200 queries per second, making it much more efficient in terms of throughput compared to Pinecone.\n",
        "Query Results (Cosine Similarity):\n",
        "For Query 1, the results are in line with the previous dataset, showing sports as the top category with the highest cosine similarity score of 14.87 (likely the distance metric in Chroma, where lower distances imply higher similarity).\n",
        "Other categories are travel, healthcare, entertainment, and finance, with decreasing scores.\n",
        "3. Faiss:\n",
        "Average Query Time: 0.000108 seconds\n",
        "Faiss is extremely fast, with each query taking around 0.0001 seconds on average.\n",
        "Queries Per Second (QPS): 9258.95\n",
        "Faiss is capable of handling a staggering 9258.95 queries per second, making it the fastest of the three methods in terms of query processing.\n",
        "Query Results (Cosine Similarity):\n",
        "Query 1 shows the same results as Chroma, with the top matches being sports, travel, healthcare, entertainment, and finance.\n",
        "The cosine similarity scores are the same as Chroma's, which is expected since both systems seem to be working with similar data structures. The values (e.g., 14.87, 26.61, etc.) correspond to the distances (inverse of similarity) in Faiss.\n",
        "Summary of Performance:\n",
        "Pinecone has a decent query time but is slower compared to Chroma and Faiss. It performs about 11.5 queries per second.\n",
        "Chroma is much faster than Pinecone, with almost 200 queries per second, and provides results quickly with very low average query time.\n",
        "Faiss is the fastest, with a highly impressive query performance, processing thousands of queries per second. It matches Chroma in terms of query results and cosine similarity values.\n",
        "Key Observations:\n",
        "Cosine Similarity Scores:\n",
        "The similarity scores for all methods are consistent in terms of ranking, suggesting that the embeddings and the metric used for similarity (cosine distance) are similar.\n",
        "The scores in Chroma and Faiss (distances) are higher, which implies that these systems may use a distance metric where smaller values represent better matches, while Pinecone uses a score where higher values indicate better similarity.\n",
        "Throughput:\n",
        "Faiss outperforms both Chroma and Pinecone in terms of queries per second, indicating it is highly optimized for speed and scalability.\n",
        "Query Time:\n",
        "The average query times for Chroma and Faiss are significantly better than Pinecone, with Faiss being the best."
      ],
      "metadata": {
        "id": "mx-yG5rXL9eU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWB-ikxCL-Tx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}